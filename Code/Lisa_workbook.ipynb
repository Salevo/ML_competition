{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, cohen_kappa_score, plot_confusion_matrix, f1_score, recall_score, precision_score, classification_report "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cookies = pd.read_csv('../Data/cookies_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cookies_v2 = pd.read_csv('../Data/cookies_less_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sugar to flour ratio</th>\n",
       "      <th>sugar index</th>\n",
       "      <th>bake temp</th>\n",
       "      <th>chill time</th>\n",
       "      <th>calories</th>\n",
       "      <th>pH</th>\n",
       "      <th>grams baking soda</th>\n",
       "      <th>bake time</th>\n",
       "      <th>quality</th>\n",
       "      <th>butter type</th>\n",
       "      <th>weight</th>\n",
       "      <th>chocolate</th>\n",
       "      <th>raisins</th>\n",
       "      <th>oats</th>\n",
       "      <th>nuts</th>\n",
       "      <th>peanut butter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>9.5</td>\n",
       "      <td>300</td>\n",
       "      <td>15.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>8.10</td>\n",
       "      <td>0.44</td>\n",
       "      <td>12.1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>15.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.23</td>\n",
       "      <td>3.3</td>\n",
       "      <td>520</td>\n",
       "      <td>34.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>8.16</td>\n",
       "      <td>0.48</td>\n",
       "      <td>8.4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>12.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.18</td>\n",
       "      <td>10.5</td>\n",
       "      <td>490</td>\n",
       "      <td>41.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.35</td>\n",
       "      <td>10.5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  sugar to flour ratio  sugar index  bake temp  chill time  \\\n",
       "0           0                  0.25          9.5        300        15.0   \n",
       "1           1                  0.23          3.3        520        34.0   \n",
       "2           3                  0.18         10.5        490        41.0   \n",
       "\n",
       "   calories    pH  grams baking soda  bake time  quality  butter type  weight  \\\n",
       "0     136.0  8.10               0.44       12.1        8            1    15.2   \n",
       "1     113.0  8.16               0.48        8.4        7            1    12.4   \n",
       "2     124.0  8.14               0.35       10.5        7            1    12.2   \n",
       "\n",
       "   chocolate  raisins  oats  nuts  peanut butter  \n",
       "0          0        1     0     0              0  \n",
       "1          0        1     0     0              0  \n",
       "2          1        0     0     0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cookies.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cookies.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cookies_v2.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting data frame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cookies.drop(['quality'], axis=1)\n",
    "y = cookies['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling the x values\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scale = scaler.transform(X_train)\n",
    "X_test_scale = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegression(max_iter=700, multi_class='multinomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=700, multi_class='multinomial')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model.fit(X_train_scale, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_model.predict(X_test_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_scores(y_test, y_pred):\n",
    "    print('R2:', round(r2_score(y_test, y_pred), 3))\n",
    "    print('Accuracy Score:', round(accuracy_score(y_test, y_pred), 3))\n",
    "    print('Cohen Kappa Score:', round(cohen_kappa_score(y_test, y_pred), 3))\n",
    "    print('MSE:', round(mean_squared_error(y_test, y_pred), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.317\n",
      "Accuracy Score: 0.57\n",
      "Cohen Kappa Score: 0.333\n",
      "MSE: 0.517\n"
     ]
    }
   ],
   "source": [
    "model_scores(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k= 1\n",
      "R2: 0.609\n",
      "RMSE: 0.836\n",
      "-0.22665663744748465\n",
      "\n",
      "For k= 2\n",
      "R2: 0.693\n",
      "RMSE: 0.742\n",
      "-0.049000644436130725\n",
      "\n",
      "For k= 3\n",
      "R2: 0.724\n",
      "RMSE: 0.703\n",
      "0.02129077409973512\n",
      "\n",
      "For k= 4\n",
      "R2: 0.737\n",
      "RMSE: 0.686\n",
      "0.050432436050504736\n",
      "\n",
      "For k= 5\n",
      "R2: 0.747\n",
      "RMSE: 0.674\n",
      "0.07284313189593006\n",
      "\n",
      "For k= 6\n",
      "R2: 0.752\n",
      "RMSE: 0.666\n",
      "0.08581369935852678\n",
      "\n",
      "For k= 7\n",
      "R2: 0.757\n",
      "RMSE: 0.66\n",
      "0.09751613956063254\n",
      "\n",
      "For k= 8\n",
      "R2: 0.762\n",
      "RMSE: 0.652\n",
      "0.11009054638368376\n",
      "\n",
      "For k= 9\n",
      "R2: 0.761\n",
      "RMSE: 0.654\n",
      "0.10775620751027493\n",
      "\n",
      "For k= 10\n",
      "R2: 0.762\n",
      "RMSE: 0.653\n",
      "0.10815921889175784\n",
      "\n",
      "For k= 11\n",
      "R2: 0.761\n",
      "RMSE: 0.654\n",
      "0.10683827444626703\n",
      "\n",
      "For k= 12\n",
      "R2: 0.76\n",
      "RMSE: 0.656\n",
      "0.10442786881625954\n",
      "\n",
      "For k= 13\n",
      "R2: 0.761\n",
      "RMSE: 0.655\n",
      "0.10575608065433018\n",
      "\n",
      "For k= 14\n",
      "R2: 0.762\n",
      "RMSE: 0.653\n",
      "0.1088872463952143\n",
      "\n",
      "For k= 15\n",
      "R2: 0.762\n",
      "RMSE: 0.653\n",
      "0.10911382844310025\n",
      "\n",
      "For k= 16\n",
      "R2: 0.761\n",
      "RMSE: 0.654\n",
      "0.10732433209784176\n",
      "\n",
      "For k= 17\n",
      "R2: 0.761\n",
      "RMSE: 0.654\n",
      "0.10792286990016187\n",
      "\n",
      "For k= 18\n",
      "R2: 0.763\n",
      "RMSE: 0.652\n",
      "0.11049672524025955\n",
      "\n",
      "For k= 19\n",
      "R2: 0.762\n",
      "RMSE: 0.653\n",
      "0.1094207435361031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#with Standard Scaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "X = cookies_v2.drop(['quality'], axis=1)\n",
    "y = cookies_v2['quality']\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#scaling the x values\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scale = scaler.transform(X_train)\n",
    "X_test_scale = scaler.transform(X_test)\n",
    "\n",
    "for k in range(1, 20):\n",
    "    Knn = KNeighborsRegressor(n_neighbors = k, weights = 'distance')\n",
    "    Knn.fit(X_train_scale, y_train)\n",
    "    y_pred = Knn.predict(X_test_scale)\n",
    "    print('For k =', k)\n",
    "    print('R2:', round(r2_score(y_test, y_pred), 3))\n",
    "    print('RMSE:', round(mean_squared_error(y_test, y_pred, squared=False), 3))\n",
    "    print(r2_score(y_test, y_pred) - mean_squared_error(y_test, y_pred, squared=False))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k= 1\n",
      "R2: 0.369\n",
      "RMSE: 0.702\n",
      "-0.33320302486666176\n",
      "\n",
      "For k= 2\n",
      "R2: 0.466\n",
      "RMSE: 0.646\n",
      "-0.1797714579742421\n",
      "\n",
      "For k= 3\n",
      "R2: 0.519\n",
      "RMSE: 0.613\n",
      "-0.09478535040046154\n",
      "\n",
      "For k= 4\n",
      "R2: 0.556\n",
      "RMSE: 0.589\n",
      "-0.03290839492041431\n",
      "\n",
      "For k= 5\n",
      "R2: 0.567\n",
      "RMSE: 0.582\n",
      "-0.01541961080010279\n",
      "\n",
      "For k= 6\n",
      "R2: 0.577\n",
      "RMSE: 0.575\n",
      "0.0017013402231457198\n",
      "\n",
      "For k= 7\n",
      "R2: 0.578\n",
      "RMSE: 0.574\n",
      "0.0044443984550760485\n",
      "\n",
      "For k= 8\n",
      "R2: 0.582\n",
      "RMSE: 0.571\n",
      "0.011075348377005523\n",
      "\n",
      "For k= 9\n",
      "R2: 0.587\n",
      "RMSE: 0.568\n",
      "0.018595142693164535\n",
      "\n",
      "For k= 10\n",
      "R2: 0.593\n",
      "RMSE: 0.564\n",
      "0.02887435394836002\n",
      "\n",
      "For k= 11\n",
      "R2: 0.6\n",
      "RMSE: 0.559\n",
      "0.0409575982917868\n",
      "\n",
      "For k= 12\n",
      "R2: 0.6\n",
      "RMSE: 0.559\n",
      "0.04147929228111946\n",
      "\n",
      "For k= 13\n",
      "R2: 0.6\n",
      "RMSE: 0.559\n",
      "0.0416155837022798\n",
      "\n",
      "For k= 14\n",
      "R2: 0.599\n",
      "RMSE: 0.56\n",
      "0.03968074105979402\n",
      "\n",
      "For k= 15\n",
      "R2: 0.604\n",
      "RMSE: 0.557\n",
      "0.04689806660817608\n",
      "\n",
      "For k= 16\n",
      "R2: 0.607\n",
      "RMSE: 0.554\n",
      "0.05253945303768193\n",
      "\n",
      "For k= 17\n",
      "R2: 0.607\n",
      "RMSE: 0.554\n",
      "0.052556105359243266\n",
      "\n",
      "For k= 18\n",
      "R2: 0.608\n",
      "RMSE: 0.553\n",
      "0.055230453273694136\n",
      "\n",
      "For k= 19\n",
      "R2: 0.608\n",
      "RMSE: 0.553\n",
      "0.054849247549396574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#with Standard Scaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "X = cookies.drop(['quality'], axis=1)\n",
    "y = cookies['quality']\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#scaling the x values\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scale = scaler.transform(X_train)\n",
    "X_test_scale = scaler.transform(X_test)\n",
    "\n",
    "for k in range(1, 20):\n",
    "    Knn = KNeighborsRegressor(n_neighbors = k, weights = 'distance')\n",
    "    Knn.fit(X_train_scale, y_train)\n",
    "    y_pred = Knn.predict(X_test_scale)\n",
    "    print('For k =', k)\n",
    "    print('R2:', round(r2_score(y_test, y_pred), 3))\n",
    "    print('RMSE:', round(np.sqrt(mean_squared_error(y_test, y_pred)), 3))\n",
    "    print(r2_score(y_test, y_pred) - mean_squared_error(y_test, y_pred, squared=False))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.395\n",
      "RMSE: 0.688\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#with Standard Scaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "X = cookies.drop(['quality'], axis=1)\n",
    "y = cookies['quality']\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#scaling the x values\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scale = scaler.transform(X_train)\n",
    "X_test_scale = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "Knn = KNeighborsRegressor(metric='wminkowski', p=2, \n",
    "                           metric_params={'w': np.random.random(X_train.shape[1])})\n",
    "Knn.fit(X_train_scale, y_train)\n",
    "y_pred = Knn.predict(X_test_scale)\n",
    "print('R2:', round(r2_score(y_test, y_pred), 3))\n",
    "print('RMSE:', round(np.sqrt(mean_squared_error(y_test, y_pred)), 3))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k = 1\n",
      "R2: 0.341\n",
      "RMSE: 0.718\n",
      "-0.3768023091868492\n",
      "\n",
      "For k = 2\n",
      "R2: 0.422\n",
      "RMSE: 0.672\n",
      "-0.2497996645079934\n",
      "\n",
      "For k = 3\n",
      "R2: 0.432\n",
      "RMSE: 0.666\n",
      "-0.23379090436420003\n",
      "\n",
      "For k = 4\n",
      "R2: 0.437\n",
      "RMSE: 0.663\n",
      "-0.22663964873265885\n",
      "\n",
      "For k = 5\n",
      "R2: 0.446\n",
      "RMSE: 0.658\n",
      "-0.21131767083957242\n",
      "\n",
      "For k = 6\n",
      "R2: 0.459\n",
      "RMSE: 0.65\n",
      "-0.19185498557058167\n",
      "\n",
      "For k = 7\n",
      "R2: 0.463\n",
      "RMSE: 0.648\n",
      "-0.18493899652364798\n",
      "\n",
      "For k = 8\n",
      "R2: 0.467\n",
      "RMSE: 0.646\n",
      "-0.179010477465264\n",
      "\n",
      "For k = 9\n",
      "R2: 0.466\n",
      "RMSE: 0.646\n",
      "-0.1804742494553001\n",
      "\n",
      "For k = 10\n",
      "R2: 0.465\n",
      "RMSE: 0.647\n",
      "-0.18152430550098175\n",
      "\n",
      "For k = 11\n",
      "R2: 0.465\n",
      "RMSE: 0.646\n",
      "-0.18104514978058506\n",
      "\n",
      "For k = 12\n",
      "R2: 0.471\n",
      "RMSE: 0.643\n",
      "-0.17227538946007848\n",
      "\n",
      "For k = 13\n",
      "R2: 0.473\n",
      "RMSE: 0.642\n",
      "-0.16951447558868082\n",
      "\n",
      "For k = 14\n",
      "R2: 0.472\n",
      "RMSE: 0.642\n",
      "-0.1705980071093558\n",
      "\n",
      "For k = 15\n",
      "R2: 0.473\n",
      "RMSE: 0.642\n",
      "-0.16891172670792598\n",
      "\n",
      "For k = 16\n",
      "R2: 0.472\n",
      "RMSE: 0.642\n",
      "-0.1696992805538825\n",
      "\n",
      "For k = 17\n",
      "R2: 0.473\n",
      "RMSE: 0.642\n",
      "-0.16862627655651075\n",
      "\n",
      "For k = 18\n",
      "R2: 0.473\n",
      "RMSE: 0.642\n",
      "-0.1685500500365027\n",
      "\n",
      "For k = 19\n",
      "R2: 0.469\n",
      "RMSE: 0.644\n",
      "-0.17532623777097112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X = cookies.drop(['quality'], axis=1)\n",
    "y = cookies['quality']\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#scaling the x values\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scale = scaler.transform(X_train)\n",
    "X_test_scale = scaler.transform(X_test)\n",
    "\n",
    "for k in range(1, 20):\n",
    "    Knn = KNeighborsRegressor(n_neighbors = k)\n",
    "    Knn.fit(X_train_scale, y_train)\n",
    "    y_pred = Knn.predict(X_test_scale)\n",
    "    print('For k =', k)\n",
    "    print('R2:', round(r2_score(y_test, y_pred), 3))\n",
    "    print('RMSE:', round(np.sqrt(mean_squared_error(y_test, y_pred)), 3))\n",
    "    print(r2_score(y_test, y_pred) - mean_squared_error(y_test, y_pred, squared=False))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k= 1\n",
      "R2: 0.369\n",
      "RMSE: 0.702\n",
      "\n",
      "For k= 2\n",
      "R2: 0.408\n",
      "RMSE: 0.68\n",
      "\n",
      "For k= 3\n",
      "R2: 0.436\n",
      "RMSE: 0.664\n",
      "\n",
      "For k= 4\n",
      "R2: 0.457\n",
      "RMSE: 0.651\n",
      "\n",
      "For k= 5\n",
      "R2: 0.46\n",
      "RMSE: 0.65\n",
      "\n",
      "For k= 6\n",
      "R2: 0.458\n",
      "RMSE: 0.651\n",
      "\n",
      "For k= 7\n",
      "R2: 0.455\n",
      "RMSE: 0.652\n",
      "\n",
      "For k= 8\n",
      "R2: 0.456\n",
      "RMSE: 0.652\n",
      "\n",
      "For k= 9\n",
      "R2: 0.46\n",
      "RMSE: 0.649\n",
      "\n",
      "For k= 10\n",
      "R2: 0.466\n",
      "RMSE: 0.646\n",
      "\n",
      "For k= 11\n",
      "R2: 0.474\n",
      "RMSE: 0.641\n",
      "\n",
      "For k= 12\n",
      "R2: 0.47\n",
      "RMSE: 0.644\n",
      "\n",
      "For k= 13\n",
      "R2: 0.467\n",
      "RMSE: 0.645\n",
      "\n",
      "For k= 14\n",
      "R2: 0.464\n",
      "RMSE: 0.647\n",
      "\n",
      "For k= 15\n",
      "R2: 0.469\n",
      "RMSE: 0.644\n",
      "\n",
      "For k= 16\n",
      "R2: 0.471\n",
      "RMSE: 0.643\n",
      "\n",
      "For k= 17\n",
      "R2: 0.468\n",
      "RMSE: 0.645\n",
      "\n",
      "For k= 18\n",
      "R2: 0.468\n",
      "RMSE: 0.645\n",
      "\n",
      "For k= 19\n",
      "R2: 0.468\n",
      "RMSE: 0.645\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#with Standard Scaler and dropping more columns\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "X = cookies.drop(['quality'], axis=1)\n",
    "y = cookies['quality']\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#scaling the x values\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scale = scaler.transform(X_train)\n",
    "X_test_scale = scaler.transform(X_test)\n",
    "\n",
    "for k in range(1, 20):\n",
    "    Knn = KNeighborsRegressor(n_neighbors = k)\n",
    "    Knn.fit(X_train_scale, y_train)\n",
    "    y_pred = Knn.predict(X_test_scale)\n",
    "    print('For k=', k)\n",
    "    print('R2:', round(r2_score(y_test, y_pred), 3))\n",
    "    print('RMSE:', round(np.sqrt(mean_squared_error(y_test, y_pred)), 3))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.463\n",
      "RMSE: 0.6476841166543369\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = cookies.drop(['quality'], axis=1)\n",
    "y = cookies['quality']\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#scaling the x values\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scale = scaler.transform(X_train)\n",
    "X_test_scale = scaler.transform(X_test)\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train_scale, y_train)\n",
    "\n",
    "y_pred = reg.predict(X_test_scale)\n",
    "y_test_predict= RFR.predict(X_test)\n",
    "\n",
    "print('R2:', round(r2_score(y_test, y_pred), 3))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6931989983754325\n",
      "R2 Score: 0.38516132557588123\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "X = cookies.drop(['quality'], axis=1)\n",
    "y = cookies['quality']\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#scaling the x values\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scale = scaler.transform(X_train)\n",
    "X_test_scale = scaler.transform(X_test)\n",
    "\n",
    "model_lasso = linear_model.Lasso(alpha=0.1)\n",
    "model_lasso.fit(X_train_scale, y_train) \n",
    "\n",
    "pred_test_lasso= model_lasso.predict(X_test_scale)\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test,pred_test_lasso))) \n",
    "print('R2 Score:', r2_score(y_test, pred_test_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.7000303851541965\n",
      "R2 Score: 0.10430073937533246\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "X = cookies.drop(['quality'], axis=1)\n",
    "y = cookies['quality']\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#scaling the x values\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scale = scaler.transform(X_train)\n",
    "X_test_scale = scaler.transform(X_test)\n",
    "\n",
    "model_lasso = linear_model.Lasso(alpha=0.1)\n",
    "model_lasso.fit(X_train_scale, y_train) \n",
    "\n",
    "pred_test_lasso= model_lasso.predict(X_test_scale)\n",
    "print('MSE:', mean_squared_error(y_test,pred_test_lasso)) \n",
    "print('R2 Score:', r2_score(y_test, pred_test_lasso))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.647684209640602\n",
      "R2 Score: 0.46325013615401944\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "X = cookies.drop(['quality'], axis=1)\n",
    "y = cookies['quality']\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#scaling the x values\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scale = scaler.transform(X_train)\n",
    "X_test_scale = scaler.transform(X_test)\n",
    "\n",
    "rr = Ridge(alpha=0.01)\n",
    "rr.fit(X_train_scale, y_train) \n",
    "\n",
    "pred_test_rr= rr.predict(X_test_scale)\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test,pred_test_rr))) \n",
    "print('R2 Score:', r2_score(y_test, pred_test_rr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.6476860253845842\n",
      "R2 Score: 0.4632471266574566\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "X = cookies.drop(['quality'], axis=1)\n",
    "y = cookies['quality']\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#scaling the x values\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scale = scaler.transform(X_train)\n",
    "X_test_scale = scaler.transform(X_test)\n",
    "\n",
    "rr = Ridge(alpha=0.01)\n",
    "rr.fit(X_train_scale, y_train) \n",
    "\n",
    "pred_test_rr= rr.predict(X_test_scale)\n",
    "print('MSE:', np.sqrt(mean_squared_error(y_test,pred_test_rr))) \n",
    "print('R2 Score:', r2_score(y_test, pred_test_rr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ElasticNet Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6490247278134731\n",
      "R2 Score: 0.46102600427679885\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "X = cookies.drop(['quality'], axis=1)\n",
    "y = cookies['quality']\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#scaling the x values\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scale = scaler.transform(X_train)\n",
    "X_test_scale = scaler.transform(X_test)\n",
    "\n",
    "model_enet = ElasticNet(alpha = 0.01)\n",
    "model_enet.fit(X_train_scale, y_train) \n",
    "\n",
    "pred_test_model_enet= model_enet.predict(X_test_scale)\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, pred_test_model_enet))) \n",
    "print('R2 Score:', r2_score(y_test, pred_test_model_enet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6476860253845842\n",
      "R2 Score: 0.4632471266574566\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "X = cookies.drop(['quality'], axis=1)\n",
    "y = cookies['quality']\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#scaling the x values\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scale = scaler.transform(X_train)\n",
    "X_test_scale = scaler.transform(X_test)\n",
    "\n",
    "model_enet = ElasticNet(alpha = 0.01)\n",
    "model_enet.fit(X_train_scale, y_train) \n",
    "\n",
    "\n",
    "pred_test_enet= rr.predict(X_test_scale)\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, pred_test_enet))) \n",
    "print('R2 Score:', r2_score(y_test, pred_test_enet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forrests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score 0.5950828024900405\n",
      "RMSE: 0.5625491190515192\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X = cookies.drop(['quality'], axis=1)\n",
    "y = cookies['quality']\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "RFR = RandomForestRegressor(max_depth=15)\n",
    "\n",
    "RFR.fit(X_train, y_train)\n",
    "\n",
    "y_pred = RFR.predict(X_train)\n",
    "y_test_pred= RFR.predict(X_test)\n",
    "\n",
    "print('R2 Score', r2_score(y_test, y_test_pred))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming test data frame\n",
    "\n",
    "test = pd.read_csv('../Data/cookies_validate.csv')\n",
    "\n",
    "#dropping\n",
    "test.drop('id', axis=1, inplace=True)\n",
    "test.drop('quality', axis=1, inplace=True)\n",
    "test.drop(['density', 'crunch factor', 'aesthetic appeal', 'diameter'], axis=1, inplace=True)\n",
    "\n",
    "#making dummies\n",
    "#butter types\n",
    "test['butter type'] = test['butter type'].replace('melted', 1).replace('cubed', 0)\n",
    "\n",
    "#mixins\n",
    "mixins_list = ['chocolate', 'raisins', 'oats', 'nuts', 'peanut butter']\n",
    "\n",
    "for x in mixins_list:\n",
    "    test[x] = 0\n",
    "    test[x] = test['mixins'].str.contains(x).astype(int)\n",
    "\n",
    "test.drop('mixins', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.64967033, 7.76968275, 7.82248288, 8.22540676, 7.60662791,\n",
       "       7.36555051, 7.94073427, 7.56140842, 7.46511562, 7.89046903,\n",
       "       7.97597346, 8.11162004, 7.25683923, 7.9033864 , 8.06106484,\n",
       "       7.77935754, 8.15597612, 7.78527173, 8.03918946, 8.51028551,\n",
       "       7.86159399, 8.49437167, 8.29754556, 7.76663937, 7.14350477,\n",
       "       7.06215909, 7.77482626, 7.33156902, 7.03197747, 7.42663106,\n",
       "       7.99567379, 7.83347024, 7.28174112, 8.24843168, 8.20817977,\n",
       "       7.86629424, 8.08834925, 8.30631707, 7.02808252, 7.80218611,\n",
       "       8.11774475, 6.75761905, 7.84093008, 7.44077743, 7.42296224,\n",
       "       7.60440728, 7.30805378, 8.19857331, 7.70764594, 7.87954272,\n",
       "       7.12182477, 7.53137318, 7.40968455, 7.9405087 , 7.80489854,\n",
       "       8.31690808, 7.71168827, 7.71444444, 7.93288668, 8.67625939,\n",
       "       7.51647604, 7.7721869 , 7.4204    , 8.22906411, 8.00611742,\n",
       "       7.84848614, 7.58138072, 7.6228658 , 7.35300673, 8.06860836,\n",
       "       8.04940664, 8.26678704, 6.55919256, 7.01686808, 8.02864642,\n",
       "       7.57691667, 7.6320083 , 7.80589727, 7.40483171, 7.9264475 ,\n",
       "       7.71423015, 7.94819922, 7.60814369, 8.65595527, 7.67417849,\n",
       "       8.19815715, 8.19815715, 8.01109517, 7.76865197, 8.50525324,\n",
       "       8.04408531, 7.59074128, 7.9287228 , 7.79289471, 7.39816517,\n",
       "       7.85357046, 7.87115644, 8.22863955, 7.8008563 , 7.27037916,\n",
       "       8.44770754, 7.60638707, 8.54859965, 7.85193287, 8.27409209,\n",
       "       8.00439323, 7.52950051, 7.09104548, 7.83173313, 8.861981  ,\n",
       "       7.79208061, 7.05939446, 7.21626077, 7.46209592, 7.86058994,\n",
       "       7.04311692, 7.74922306, 7.74922306, 8.79887989, 7.69461918,\n",
       "       7.924264  , 7.49954962, 6.98666667, 7.84914546, 7.88751   ,\n",
       "       7.85813296, 7.13365927, 8.03235623, 7.17363426, 8.2015509 ,\n",
       "       7.20505301, 8.14710715, 7.32587737, 6.9875    , 7.20016294,\n",
       "       8.75039582, 7.19939886, 8.06745733, 8.01732493, 8.01732493,\n",
       "       7.70499203, 7.70499203, 7.16548291, 7.45991657, 7.69633829,\n",
       "       7.16405373, 7.70627818, 8.06784347, 8.23340707, 8.31179651,\n",
       "       6.97667825, 8.02384747, 7.90343952, 7.12921588, 7.14216637,\n",
       "       7.73309112, 7.91172028, 7.12368686, 8.27075518, 8.90926293,\n",
       "       7.9172533 , 7.57306156, 7.50170781, 8.29199734, 7.68939297,\n",
       "       7.51955357, 7.43097987, 7.53174605, 7.37636796, 7.79829477,\n",
       "       8.93472737, 7.85236064, 7.29202841, 7.79109652, 7.6015036 ,\n",
       "       8.28899964, 8.57686583, 7.92524965, 7.96647959, 8.12134508,\n",
       "       7.39861385, 7.49248839, 7.6643052 , 7.13017315, 7.09168928,\n",
       "       6.48220613, 7.6006267 , 7.09286346, 7.50321219, 8.07638469,\n",
       "       7.05881762, 7.01116803, 8.21397233, 7.26666667, 8.25272316,\n",
       "       8.08505649, 7.21566418, 7.21566418, 8.7926098 , 8.07122681,\n",
       "       7.71534448, 8.65883356, 8.4695557 , 7.24894693, 8.40144177,\n",
       "       7.28344869, 7.11118027, 7.40655486, 7.37283156, 8.01488249,\n",
       "       7.37854197, 7.26038325, 7.21      , 7.58985672, 7.5155602 ,\n",
       "       7.72069712, 7.81409057, 7.7895105 , 7.48554565, 7.34      ,\n",
       "       7.34      , 7.15518375, 7.12336465, 7.87215065, 7.6633519 ,\n",
       "       7.17538245, 7.95894658, 7.24859907, 7.98133921, 7.16333333,\n",
       "       7.45113681, 7.31622551, 6.53831616, 7.8328873 , 7.60392044,\n",
       "       8.56286633, 8.64557883, 7.61909091, 8.72473615, 7.73804676,\n",
       "       7.69576976, 7.61683457, 7.85127782, 7.07154667, 7.71636988,\n",
       "       7.21990387, 7.63255276, 7.82921673, 7.72463511, 7.46931405,\n",
       "       7.62487545, 8.99793103, 6.88159402, 8.06128463, 7.35499572,\n",
       "       8.79595455, 7.69822626, 7.1706586 , 7.90037037, 7.44      ,\n",
       "       8.48407564, 6.98160714, 7.26462363, 8.48682192, 7.97916645,\n",
       "       7.92571396, 7.12407353, 7.17910579, 7.7062753 , 7.9166552 ,\n",
       "       8.82569125, 7.7119723 , 7.54789016, 7.03866332, 8.51892873,\n",
       "       7.2157352 , 8.09661425, 8.15638363, 8.20949758, 8.54164594,\n",
       "       7.35896666, 7.88270581, 7.4124837 , 7.61076149, 8.16157579,\n",
       "       7.93041921, 7.36      , 7.3831183 , 8.94378941, 7.11224727,\n",
       "       8.19571872, 8.21402667, 7.74891815, 7.73015868, 7.65905424,\n",
       "       8.39553281, 8.40087307, 7.63522761, 7.48862121, 7.77550641,\n",
       "       7.83410673, 8.08731394, 7.80940934, 7.62348803, 7.64816219,\n",
       "       8.61005709, 8.62791625, 8.37271679, 8.14688896, 8.30138953,\n",
       "       8.05055789, 8.06458582, 8.18029075, 7.6874975 , 8.46640706,\n",
       "       7.05746032, 7.77975332, 7.35335995, 8.0215455 , 8.69812078,\n",
       "       8.00853584, 8.11707379, 8.11707379, 8.28728591, 7.42618683,\n",
       "       7.42810525, 7.95177778, 8.03130784, 7.9035    , 8.26880962,\n",
       "       7.12313791, 8.6296095 , 7.70703072, 7.35      , 8.34829515,\n",
       "       8.13766785, 8.32722013, 7.27624651, 8.87963586, 8.40582643,\n",
       "       6.73      , 6.86672874, 7.54928013, 8.53971928, 8.53971928,\n",
       "       7.92223841, 8.27146902, 7.16568727, 7.86708361, 7.17438366,\n",
       "       7.73054537, 7.50818966, 7.60989394, 8.37215808, 8.01446679,\n",
       "       7.50818966, 7.46101246, 7.43231562, 8.14103049, 8.18120182,\n",
       "       7.98176706, 8.30465751, 6.7       , 8.11624374, 8.30465751,\n",
       "       7.86857088, 7.61993717, 7.37485346, 8.15735714, 7.27057724,\n",
       "       8.11770211, 8.29902932, 7.65069978, 8.05651564, 7.7062158 ,\n",
       "       8.40877551, 7.94456465, 8.72987352, 8.87186692, 8.66176472,\n",
       "       8.06274333, 8.22841832, 7.30416933, 8.14748466, 7.95432615,\n",
       "       8.00537114, 7.99976569, 8.59472139, 8.59730823, 7.42188702,\n",
       "       8.42788142, 7.98724432, 7.98724432, 8.82618391, 8.32677677,\n",
       "       8.68024971, 7.19211034, 7.22893236, 7.45821028, 8.24141068,\n",
       "       8.26362193, 6.9176849 , 8.40487379, 8.44490159, 8.88563961,\n",
       "       8.07660241, 7.76912546, 7.5705    , 8.27688533, 7.88714018,\n",
       "       8.27669252, 8.33973887, 7.39495728, 8.13866309, 7.39495728,\n",
       "       7.92336324, 8.82327304, 7.86909764, 8.17185231, 8.62483379,\n",
       "       8.0728491 , 8.1572596 , 8.56145824, 8.18261146, 8.19541056,\n",
       "       7.18375351, 8.38216931, 7.52732027, 7.67638568, 8.63293646,\n",
       "       8.81785794, 7.00116667, 7.58421594, 8.20122002, 8.68765989,\n",
       "       7.3220322 , 8.4563054 , 7.83205302, 8.57117206, 7.78837037,\n",
       "       8.00897985, 8.52583815, 8.39554766, 8.39554766, 7.61960324,\n",
       "       8.56278109, 7.9094078 , 7.18788433, 8.11211647, 8.41838278,\n",
       "       8.0577704 , 7.82255051, 7.93589902, 7.59727222, 7.74043561,\n",
       "       7.83155878, 7.74043561, 7.95135297, 7.62196029, 7.62196029,\n",
       "       8.77901259, 8.18060677, 8.45140852, 8.13667566, 7.95314797,\n",
       "       7.54674618, 7.78350376, 7.54674618, 7.40161841, 6.95840294,\n",
       "       8.31431538, 8.27846986, 8.61984407, 6.86777778, 7.61027718,\n",
       "       7.80763688, 8.21056387, 7.07683804, 8.19529131, 8.24806612,\n",
       "       8.40614094, 8.10812526, 7.2391538 , 7.14487577, 7.39836658,\n",
       "       8.60319316, 8.0672902 , 7.44933587, 8.96865603, 8.25625292,\n",
       "       7.48009977, 7.87983523, 7.59913043, 8.64743625, 7.75080752,\n",
       "       8.6558511 , 8.43083274, 8.14025404, 7.25454427, 7.26319917,\n",
       "       6.995     , 6.91146443, 7.17985111, 7.34858501, 8.26668807,\n",
       "       7.53505559, 7.81070763, 8.16897666, 8.60538728, 8.55466373,\n",
       "       8.17594279, 8.67103407, 7.40772351, 7.23395967, 8.26076782,\n",
       "       7.89357581, 7.94415604, 8.31439323, 7.55965083, 8.28562257,\n",
       "       8.01396692, 8.15015825, 7.71      , 7.89720995, 8.14659113,\n",
       "       8.22938628, 8.42065058, 8.10495683, 7.12228003, 8.75440843,\n",
       "       7.24295313, 7.21098038, 8.91320786, 8.11927028, 8.11927028,\n",
       "       7.99772196, 7.82066285, 7.55477747, 7.97668032, 7.55477747,\n",
       "       6.94      , 8.76030981, 8.23235804, 7.72600175, 8.18196154,\n",
       "       7.23031162, 7.23031162, 8.22035714, 8.08957773, 8.84007811,\n",
       "       7.68701644, 7.57863198, 7.91414113, 7.83229991, 7.85734012,\n",
       "       7.15167421, 7.92536762, 7.76496515, 7.06541779, 8.01149847,\n",
       "       8.45300182, 7.90573561, 8.17417742, 7.46611528, 7.41625764,\n",
       "       7.12953187, 7.18102381, 7.18102381, 8.00427453, 7.26067137,\n",
       "       7.26067137, 9.        , 9.        , 7.94012134, 7.43608456,\n",
       "       7.94199981, 7.94388174, 7.17707686, 7.41767069, 8.12615278,\n",
       "       7.0812384 , 6.79      , 8.42973351, 8.2826184 , 7.85416163,\n",
       "       8.27711197, 8.43367929, 7.39793094, 8.05165989, 7.62986409,\n",
       "       8.35906848, 8.09211052, 8.35906848, 8.40454743, 7.59448969,\n",
       "       6.99517809, 8.03866504, 7.7160719 , 8.47268177, 8.23860434,\n",
       "       8.29774387, 8.8321603 , 8.30893428, 8.80220372, 7.58845296,\n",
       "       8.03752298, 7.19208868, 7.14442776, 7.13371867, 8.1132063 ,\n",
       "       7.9320102 , 8.01247054, 8.09252803, 8.02934846, 8.05139543,\n",
       "       7.31556062, 7.39213014, 7.39213014, 7.95934555, 7.93805281,\n",
       "       7.93805281, 7.80379921, 7.97733061, 8.38444533, 7.25850055,\n",
       "       7.94765472, 7.27213091, 7.27213091, 7.64549525, 8.28712315,\n",
       "       7.93990417, 8.45697268, 6.82966134, 7.24536775, 8.20877691,\n",
       "       7.20347417, 8.14994953, 7.04176206, 7.96703732, 8.00038992,\n",
       "       7.28490486, 7.28076674, 8.24701438, 8.09366775, 7.70992178,\n",
       "       8.25344788, 8.36801259, 8.09160917, 8.56946677, 8.15767948,\n",
       "       8.60869937, 6.83166667, 8.44419136, 8.26813589, 8.26717015,\n",
       "       8.40076877, 7.13      , 8.26384416, 8.20342869, 8.42212619,\n",
       "       8.52193625, 7.77697284, 7.97371403, 7.77812739, 7.98043612,\n",
       "       7.98043612, 7.49515769, 8.39626025, 7.99579199, 7.6605    ,\n",
       "       8.09915435, 7.92727728, 8.01816085, 8.16596443, 7.9040641 ,\n",
       "       8.29217361, 7.97218323, 8.81186355, 7.88091562, 8.45285007,\n",
       "       7.52585069, 8.30593469, 7.72069886, 7.5464237 , 7.9       ,\n",
       "       8.2788646 , 8.0416308 , 7.17895025, 7.56308078, 7.66859525,\n",
       "       7.66859525, 8.44209332, 8.18743456, 7.14117277, 8.52253203,\n",
       "       7.13      , 7.25594017, 7.7525814 , 8.71305562, 6.918     ,\n",
       "       7.56112769, 8.16049828, 7.56112769, 8.0926003 , 8.28413827,\n",
       "       8.41112861, 6.38      , 6.11      , 6.        , 6.04      ,\n",
       "       6.01      , 6.1       , 6.14      , 6.07      , 6.13      ,\n",
       "       6.        , 6.03      , 6.24      , 6.72      , 6.47      ,\n",
       "       6.1       , 6.42      , 6.92      , 6.83      , 6.21      ,\n",
       "       6.53      , 7.08      , 6.46      , 6.42      , 6.27      ,\n",
       "       6.4       , 6.11      , 6.48      , 6.3       , 6.81      ,\n",
       "       6.1       , 6.36      , 6.16      , 6.54      , 6.04      ,\n",
       "       6.02      , 6.07      , 6.64      , 6.5       , 6.06      ,\n",
       "       6.15      , 6.23      , 6.54      , 6.38      , 6.95      ,\n",
       "       6.91      , 6.1       , 6.67      , 6.68      , 6.1       ,\n",
       "       6.71      , 6.17      , 6.02      , 6.21      , 6.42      ,\n",
       "       6.36      , 6.5       , 6.12      , 6.46      , 6.        ,\n",
       "       6.12      , 6.05      , 6.        , 6.03      , 6.02      ,\n",
       "       6.79      , 6.37      , 6.61      , 6.44      , 6.04      ,\n",
       "       6.03      , 6.26      , 6.2       , 6.66      ])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quality_pred = RFR.predict(test)\n",
    "quality_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sugar to flour ratio</th>\n",
       "      <th>sugar index</th>\n",
       "      <th>bake temp</th>\n",
       "      <th>chill time</th>\n",
       "      <th>calories</th>\n",
       "      <th>pH</th>\n",
       "      <th>grams baking soda</th>\n",
       "      <th>bake time</th>\n",
       "      <th>butter type</th>\n",
       "      <th>weight</th>\n",
       "      <th>chocolate</th>\n",
       "      <th>raisins</th>\n",
       "      <th>oats</th>\n",
       "      <th>nuts</th>\n",
       "      <th>peanut butter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.62</td>\n",
       "      <td>19.25</td>\n",
       "      <td>400.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>7.98</td>\n",
       "      <td>0.67</td>\n",
       "      <td>9.7</td>\n",
       "      <td>1</td>\n",
       "      <td>16.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.35</td>\n",
       "      <td>1.00</td>\n",
       "      <td>520.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>8.45</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.39</td>\n",
       "      <td>10.40</td>\n",
       "      <td>440.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>8.20</td>\n",
       "      <td>0.53</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.33</td>\n",
       "      <td>1.10</td>\n",
       "      <td>570.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>8.32</td>\n",
       "      <td>0.46</td>\n",
       "      <td>10.9</td>\n",
       "      <td>1</td>\n",
       "      <td>12.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>13.50</td>\n",
       "      <td>600.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.44</td>\n",
       "      <td>9.1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>0.02</td>\n",
       "      <td>1.90</td>\n",
       "      <td>780.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.40</td>\n",
       "      <td>0.75</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>0.19</td>\n",
       "      <td>5.20</td>\n",
       "      <td>940.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>8.16</td>\n",
       "      <td>0.52</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.10</td>\n",
       "      <td>600.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.59</td>\n",
       "      <td>0.61</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>0.08</td>\n",
       "      <td>2.30</td>\n",
       "      <td>670.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8.52</td>\n",
       "      <td>0.57</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>0.50</td>\n",
       "      <td>13.80</td>\n",
       "      <td>2050.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>8.16</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0</td>\n",
       "      <td>19.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>779 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sugar to flour ratio  sugar index  bake temp  chill time  calories    pH  \\\n",
       "0                    0.62        19.25      400.0        41.0     172.0  7.98   \n",
       "1                    0.35         1.00      520.0        35.0     146.0  8.45   \n",
       "2                    0.39        10.40      440.0        20.0     142.0  8.20   \n",
       "3                    0.33         1.10      570.0        21.0      82.0  8.32   \n",
       "4                    0.37        13.50      600.0        52.0     192.0  8.00   \n",
       "..                    ...          ...        ...         ...       ...   ...   \n",
       "774                  0.02         1.90      780.0        18.0      30.0  8.40   \n",
       "775                  0.19         5.20      940.0        19.0      98.0  8.16   \n",
       "776                  0.00         2.10      600.0         6.0      13.0  8.59   \n",
       "777                  0.08         2.30      670.0        19.0      32.0  8.52   \n",
       "778                  0.50        13.80     2050.0        48.0      82.0  8.16   \n",
       "\n",
       "     grams baking soda  bake time  butter type  weight  chocolate  raisins  \\\n",
       "0                 0.67        9.7            1    16.6          1        0   \n",
       "1                 0.44       10.0            1    13.8          1        0   \n",
       "2                 0.53       10.0            1    17.0          1        0   \n",
       "3                 0.46       10.9            1    12.4          1        0   \n",
       "4                 0.44        9.1            1    14.8          1        0   \n",
       "..                 ...        ...          ...     ...        ...      ...   \n",
       "774               0.75        9.8            0    13.8          1        0   \n",
       "775               0.52        9.6            0    14.8          0        0   \n",
       "776               0.61       10.0            0    12.4          0        0   \n",
       "777               0.57       11.0            0    13.4          0        0   \n",
       "778               0.75        8.8            0    19.8          0        1   \n",
       "\n",
       "     oats  nuts  peanut butter  \n",
       "0       0     1              0  \n",
       "1       0     0              0  \n",
       "2       0     0              0  \n",
       "3       1     0              0  \n",
       "4       0     0              0  \n",
       "..    ...   ...            ...  \n",
       "774     1     1              0  \n",
       "775     1     1              0  \n",
       "776     1     1              0  \n",
       "777     0     0              1  \n",
       "778     0     1              0  \n",
       "\n",
       "[779 rows x 15 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['quality_pred'] = quality_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('../Data/firsttry_sarahlisa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8    1580\n",
       "7    1033\n",
       "9     672\n",
       "6     354\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cookies['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8     1778\n",
       "7     1316\n",
       "9      706\n",
       "6      614\n",
       "5      575\n",
       "10     135\n",
       "4       44\n",
       "3        8\n",
       "11       5\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cookies_v2['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third Try (weighted KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cookies_v2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-1c8d1669cfbb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKNeighborsRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcookies_v2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'quality'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcookies_v2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'quality'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cookies_v2' is not defined"
     ]
    }
   ],
   "source": [
    "#with Standard Scaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "X = cookies_v2.drop(['quality'], axis=1)\n",
    "y = cookies_v2['quality']\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#scaling the x values\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scale = scaler.transform(X_train)\n",
    "X_test_scale = scaler.transform(X_test)\n",
    "\n",
    "Knn = KNeighborsRegressor(n_neighbors = 18, weights = 'distance')\n",
    "Knn.fit(X_train_scale, y_train)\n",
    "y_pred = Knn.predict(X_test_scale)\n",
    "print('R2:', round(r2_score(y_test, y_pred), 3))\n",
    "print('RMSE:', round(mean_squared_error(y_test, y_pred, squared=False), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scaling test data set\n",
    "scaler.fit(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.38704993, 5.38722922, 5.3869995 , 5.38720569, 5.38751015,\n",
       "       5.38722751, 5.3871728 , 5.3870779 , 5.38690633, 5.38732026,\n",
       "       5.38698255, 5.3868255 , 5.38686029, 5.38640272, 5.38625202,\n",
       "       5.38707322, 5.38737022, 5.38724725, 5.38496603, 5.38658055,\n",
       "       5.38689407, 5.3873476 , 5.38604394, 5.38725817, 5.38710495,\n",
       "       5.38717786, 5.38717744, 5.38692328, 5.38735504, 5.38719867,\n",
       "       5.38736161, 5.38723377, 5.38725952, 5.38707847, 5.38648933,\n",
       "       5.38707154, 5.38692807, 5.38650497, 5.38675979, 5.38735029,\n",
       "       5.38702989, 5.3866909 , 5.38729703, 5.38655705, 5.38758883,\n",
       "       5.3874265 , 5.3877027 , 5.3866808 , 5.38723128, 5.38732877,\n",
       "       5.38702696, 5.38723363, 5.38663513, 5.38696061, 5.3872529 ,\n",
       "       5.38687857, 5.38700184, 5.38700121, 5.38628818, 5.38630421,\n",
       "       5.38745797, 5.38718304, 5.38658026, 5.38651507, 5.38692196,\n",
       "       5.38696876, 5.38712557, 5.3874057 , 5.38736811, 5.38695428,\n",
       "       5.38720493, 5.38612515, 5.38720985, 5.38712766, 5.38679893,\n",
       "       5.38718047, 5.38690269, 5.38705423, 5.38740512, 5.3869908 ,\n",
       "       5.38745429, 5.38725681, 5.38715195, 5.38746455, 5.3873886 ,\n",
       "       5.38724982, 5.38724982, 5.38687813, 5.38718909, 5.3869183 ,\n",
       "       5.38693996, 5.38727609, 5.38735275, 5.38734252, 5.38622486,\n",
       "       5.38744287, 5.38701483, 5.3871054 , 5.38660204, 5.387311  ,\n",
       "       5.38691993, 5.38759639, 5.38674949, 5.38676049, 5.38678531,\n",
       "       5.38698681, 5.3873214 , 5.3872832 , 5.38749694, 5.38667629,\n",
       "       5.38731917, 5.38720008, 5.38740409, 5.38735692, 5.38730127,\n",
       "       5.38732909, 5.38728467, 5.38728467, 5.38657375, 5.38717068,\n",
       "       5.38658865, 5.38741184, 5.38559842, 5.38660967, 5.38775186,\n",
       "       5.38608083, 5.38722495, 5.38717847, 5.38737322, 5.38703539,\n",
       "       5.38722013, 5.38713696, 5.38729231, 5.38560428, 5.38719042,\n",
       "       5.386781  , 5.38716272, 5.38749755, 5.38710399, 5.38710399,\n",
       "       5.38554349, 5.38554349, 5.38663269, 5.38606897, 5.38700041,\n",
       "       5.38725794, 5.38698081, 5.3866461 , 5.38645684, 5.38639134,\n",
       "       5.38740203, 5.38686905, 5.38707609, 5.38714326, 5.38718325,\n",
       "       5.38713097, 5.3870972 , 5.38717136, 5.38682849, 5.3865048 ,\n",
       "       5.38671353, 5.3874915 , 5.38724778, 5.38646541, 5.38733601,\n",
       "       5.38726052, 5.38704367, 5.38714198, 5.38734894, 5.38647053,\n",
       "       5.38749759, 5.38689096, 5.38688384, 5.38680754, 5.38637578,\n",
       "       5.3867506 , 5.38696366, 5.38701053, 5.3872375 , 5.38675901,\n",
       "       5.38713476, 5.38720602, 5.38712634, 5.38712652, 5.38711061,\n",
       "       5.38744373, 5.38694012, 5.38727636, 5.38760303, 5.38676359,\n",
       "       5.38825824, 5.38736488, 5.38625847, 5.38822621, 5.38687325,\n",
       "       5.38679871, 5.38739443, 5.38739443, 5.3865186 , 5.38711734,\n",
       "       5.38725218, 5.38606462, 5.38689902, 5.3874442 , 5.38689507,\n",
       "       5.38729427, 5.38709161, 5.38759666, 5.38737129, 5.38673509,\n",
       "       5.38736197, 5.38796413, 5.38638805, 5.38784256, 5.38737076,\n",
       "       5.38694993, 5.38685379, 5.38721281, 5.38768556, 5.38794398,\n",
       "       5.38794398, 5.38721441, 5.38726053, 5.38750205, 5.3867106 ,\n",
       "       5.38740355, 5.38689848, 5.38688397, 5.38687283, 5.38624249,\n",
       "       5.38697694, 5.3877291 , 5.38725956, 5.38703807, 5.38712043,\n",
       "       5.38660775, 5.38658233, 5.38733297, 5.38647833, 5.38677275,\n",
       "       5.38661963, 5.38690223, 5.38695035, 5.38717993, 5.38691189,\n",
       "       5.3874788 , 5.38728105, 5.38662962, 5.3871245 , 5.38737098,\n",
       "       5.38733968, 5.38749126, 5.38755929, 5.44268622, 5.38734609,\n",
       "       5.38680446, 5.38694415, 5.38716494, 5.38726408, 5.38680992,\n",
       "       5.38506799, 5.38791953, 5.38755038, 5.3861017 , 5.38674905,\n",
       "       5.38671363, 5.38679036, 5.38720919, 5.38570151, 5.3867554 ,\n",
       "       5.38617223, 5.38710869, 5.38744768, 5.3871112 , 5.38638397,\n",
       "       5.38714585, 5.38731069, 5.38720431, 5.38654268, 5.38633203,\n",
       "       5.38759959, 5.38729192, 5.38742648, 5.38703167, 5.386225  ,\n",
       "       5.38683687, 5.38768117, 5.38777612, 5.38639863, 5.38727209,\n",
       "       5.38621508, 5.38678747, 5.38687679, 5.38692073, 5.38716003,\n",
       "       5.3871749 , 5.38582866, 5.38726163, 5.38756279, 5.38718417,\n",
       "       5.38701374, 5.38631855, 5.38687609, 5.38831666, 5.38697039,\n",
       "       5.38650957, 5.3865834 , 5.38590774, 5.38606994, 5.38644039,\n",
       "       5.38686263, 5.3859767 , 5.3865329 , 5.38694792, 5.38672285,\n",
       "       5.38753181, 5.38609996, 5.38764303, 5.38631691, 5.38596859,\n",
       "       5.38728483, 5.38663056, 5.38663056, 5.38460616, 5.38620809,\n",
       "       5.3871668 , 5.3869919 , 5.38664   , 5.38582068, 5.38676009,\n",
       "       5.38800454, 5.38623407, 5.38632023, 5.38618505, 5.3864621 ,\n",
       "       5.38675354, 5.38645316, 5.38707093, 5.38696086, 5.38559405,\n",
       "       5.38561245, 5.38686593, 5.38679378, 5.38643621, 5.38643621,\n",
       "       5.38738814, 5.38605285, 5.38725406, 5.38701178, 5.38824284,\n",
       "       5.38716617, 5.38720719, 5.38584849, 5.38670234, 5.38645619,\n",
       "       5.38720719, 5.38641914, 5.3872077 , 5.38539769, 5.38597266,\n",
       "       5.38701198, 5.38694607, 5.38570424, 5.38650914, 5.38694607,\n",
       "       5.38703969, 5.38742912, 5.3869092 , 5.38645278, 5.38678022,\n",
       "       5.38674741, 5.38710928, 5.38671399, 5.38682687, 5.38753209,\n",
       "       5.38582725, 5.38680374, 5.38632313, 5.38591179, 5.38673352,\n",
       "       5.38655881, 5.38724966, 5.3867451 , 5.38712096, 5.38614044,\n",
       "       5.38708836, 5.38700267, 5.3867281 , 5.38638111, 5.38732388,\n",
       "       5.38688456, 5.38724538, 5.38724538, 5.38610291, 5.38622464,\n",
       "       5.38678537, 5.38679462, 5.38756764, 5.38688892, 5.3871471 ,\n",
       "       5.38647411, 5.38671342, 5.38668918, 5.38616472, 5.38666255,\n",
       "       5.38646551, 5.38729392, 5.38673571, 5.38634965, 5.3861154 ,\n",
       "       5.38672414, 5.3871254 , 5.38734759, 5.38651244, 5.38734759,\n",
       "       5.38722452, 5.38679056, 5.38740853, 5.38699662, 5.38646144,\n",
       "       5.38626985, 5.38640942, 5.38659249, 5.38652926, 5.38672273,\n",
       "       5.38738499, 5.38615716, 5.38733598, 5.38756117, 5.38683666,\n",
       "       5.38661007, 5.38663075, 5.38726398, 5.38687054, 5.38663752,\n",
       "       5.38737254, 5.38641849, 5.38699651, 5.386586  , 5.38722914,\n",
       "       5.38708363, 5.38678058, 5.38640784, 5.38640784, 5.38727402,\n",
       "       5.38662292, 5.38639097, 5.38720575, 5.38605251, 5.38576402,\n",
       "       5.38675346, 5.38743678, 5.3868942 , 5.38559815, 5.38619443,\n",
       "       5.38639683, 5.38619443, 5.38718753, 5.38682379, 5.38682379,\n",
       "       5.38708543, 5.38648124, 5.38690292, 5.38695876, 5.3864949 ,\n",
       "       5.38644284, 5.38711962, 5.38644284, 5.38678461, 5.38808314,\n",
       "       5.38517715, 5.38705339, 5.38666506, 5.38598977, 5.38775633,\n",
       "       5.38656301, 5.38722056, 5.38783323, 5.38617956, 5.38711104,\n",
       "       5.38656973, 5.38646386, 5.38766881, 5.38731022, 5.38716917,\n",
       "       5.38682127, 5.38705111, 5.38661866, 5.38721894, 5.38678794,\n",
       "       5.38728112, 5.44166051, 5.38507439, 5.3862765 , 5.38690318,\n",
       "       5.38567468, 5.38568528, 5.38537594, 5.38727932, 5.38736796,\n",
       "       5.38618735, 5.38788227, 5.38732034, 5.3870976 , 5.38678272,\n",
       "       5.3869892 , 5.38679918, 5.38585673, 5.38637831, 5.38638525,\n",
       "       5.38702556, 5.38669439, 5.38745138, 5.3876102 , 5.38704044,\n",
       "       5.38700148, 5.38702083, 5.38679714, 5.38709779, 5.38650329,\n",
       "       5.38703594, 5.38699534, 5.38112568, 5.38818711, 5.38652631,\n",
       "       5.3868873 , 5.38661396, 5.38648142, 5.38741496, 5.38650218,\n",
       "       5.38835405, 5.38754614, 5.38643735, 5.38656088, 5.38656088,\n",
       "       5.38671226, 5.38691993, 5.38742766, 5.38686964, 5.38742766,\n",
       "       5.3867156 , 5.38692692, 5.38729568, 5.3871826 , 5.38739107,\n",
       "       5.38734981, 5.38734981, 5.38638178, 5.38637133, 5.38721346,\n",
       "       5.38719095, 5.38714838, 5.3868699 , 5.38706726, 5.38687913,\n",
       "       5.38799301, 5.38720972, 5.38654089, 5.38740048, 5.38674542,\n",
       "       5.38686654, 5.38703135, 5.38707436, 5.38709415, 5.38730045,\n",
       "       5.3874417 , 5.38734864, 5.38734864, 5.38728416, 5.38723791,\n",
       "       5.38723791, 5.38737814, 5.38737814, 5.38722643, 5.38741409,\n",
       "       5.38650519, 5.38684035, 5.38715878, 5.38716625, 5.38709492,\n",
       "       5.38749744, 5.38562857, 5.3859795 , 5.38743023, 5.38597355,\n",
       "       5.38668025, 5.3868464 , 5.38669512, 5.38673753, 5.38708612,\n",
       "       5.38684883, 5.38688511, 5.38684883, 5.38689804, 5.38734515,\n",
       "       5.38798098, 5.38688539, 5.38715812, 5.38671434, 5.386689  ,\n",
       "       5.38685911, 5.38653985, 5.3868126 , 5.38737216, 5.38681423,\n",
       "       5.38642172, 5.38729173, 5.38756125, 5.3871011 , 5.3868144 ,\n",
       "       5.38664294, 5.38717528, 5.3871138 , 5.38661595, 5.38673386,\n",
       "       5.38739873, 5.38734106, 5.38734106, 5.38678884, 5.38701963,\n",
       "       5.38701963, 5.38702268, 5.38705964, 5.38667417, 5.38751272,\n",
       "       5.38726514, 5.38720869, 5.38720869, 5.38729998, 5.38676199,\n",
       "       5.38672459, 5.38655636, 5.38728024, 5.38719706, 5.38613247,\n",
       "       5.38733591, 5.38644688, 5.38755594, 5.38744965, 5.38726597,\n",
       "       5.38640495, 5.38725345, 5.38599374, 5.38672084, 5.38591251,\n",
       "       5.38676007, 5.38670019, 5.3864899 , 5.38662164, 5.38633958,\n",
       "       5.38665868, 5.38677931, 5.38680845, 5.38661958, 5.38613499,\n",
       "       5.38659356, 5.38668875, 5.38626647, 5.38619785, 5.38648514,\n",
       "       5.38655654, 5.38672601, 5.38557763, 5.38738761, 5.38680872,\n",
       "       5.38680872, 5.38701491, 5.38645375, 5.38712475, 5.38609988,\n",
       "       5.38680549, 5.38648397, 5.38659913, 5.38666079, 5.4992903 ,\n",
       "       5.38631992, 5.38586465, 5.38652296, 5.38718589, 5.38640016,\n",
       "       5.38698469, 5.38677662, 5.38607447, 5.38716824, 5.38679829,\n",
       "       5.38642084, 5.38604922, 5.38813694, 5.38691651, 5.38695903,\n",
       "       5.38695903, 5.38646283, 5.38666295, 5.38735513, 5.38662727,\n",
       "       5.38588034, 5.38611991, 5.38534238, 5.38667908, 5.38611746,\n",
       "       5.38719602, 5.38679716, 5.38719603, 5.38629334, 5.38648487,\n",
       "       5.38580375, 5.38832613, 5.38760206, 5.38777713, 5.38737806,\n",
       "       5.38768867, 5.38738335, 5.38774757, 5.38752749, 5.38788694,\n",
       "       5.38752919, 5.38784208, 5.38725033, 5.38792806, 5.38720259,\n",
       "       5.38746366, 5.3873358 , 5.38778261, 5.3880077 , 5.38800211,\n",
       "       5.38772797, 5.3882992 , 5.38756931, 5.38747169, 5.38745887,\n",
       "       5.38741165, 5.38773932, 5.38757655, 5.38750605, 5.38728593,\n",
       "       5.38779387, 5.3875969 , 5.38746501, 5.38744401, 5.3876234 ,\n",
       "       5.38768825, 5.38781683, 5.44101102, 5.38726801, 5.38740301,\n",
       "       5.38776406, 5.38783695, 5.38770706, 5.38801748, 5.38752848,\n",
       "       5.3873915 , 5.38778526, 5.38751997, 5.38716847, 5.38788276,\n",
       "       5.38668734, 5.38755084, 5.38776446, 5.38831311, 5.38788859,\n",
       "       5.38752527, 5.3874251 , 5.38752792, 5.38743959, 5.38756455,\n",
       "       5.38758067, 5.38805981, 5.3875707 , 5.38767697, 5.38771545,\n",
       "       5.38692897, 5.38755367, 5.38841795, 5.38690326, 5.38758414,\n",
       "       5.3878444 , 5.38717544, 5.38737641, 5.38839607])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quality_pred = Knn.predict(test)\n",
    "quality_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD4CAYAAADSIzzWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAALxklEQVR4nO3dX4ydeV3H8c+3HVhwgWC2G3WBdcRJNCAqmwpBDGACSWWNSNxEL7RVY4hmLVUv1JiNMXHv9ALSRAnB1W4AiUHggl0ru9EsJkaSKWwtCJoRSmWXhDKJ+GfJYtufFzPtTqcznZlzZvqdzr5eSTPnPM+Tmd8355n3OX1Op1NjjABw4+3rXgDAs5UAAzQRYIAmAgzQRIABmsxs5eADBw6M2dnZHVoKwN506tSpr48xbl+9fUsBnp2dzfz8/PatCuBZoKq+vNZ2lyAAmggwQBMBBmgiwABNBBigiQADNBFggCYCDNBEgAGaCDBAEwEGaCLAAE0EGKCJAAM0EWCAJgIM0ESAAZoIMEATAQZosqXfCXejHT9+PI899liS5I1vfGOOHj3avCKA7bOrA7ywsJDzX1+8chtgL9nVAU6S7N/9SwSYhGvAAE0EGKCJAAM0EWCAJgIM0ESAAZoIMEATAQZoIsAATQQYoIkAAzQRYIAmAgzQRIABmggwQBMBBmgiwABNBBigiQADNBFggCYCDNBEgAGaCDBAEwEGaCLAAE0EGKCJAAM0EWCAJgIM0ESAAZoIMEATAQZoIsAATQQYoIkAAzQRYIAmAgzQRIABmggwQBMBBmgiwABNdl2Ajx8/nuPHj0+8H+BmMdO9gNUWFham2g9ws9h1r4ABni0EGKCJAAM0EWCAJgIM0ESAAZoIMEATAQZoIsAATQQYoIkAAzQRYIAmAgzQRIABmggwQBMBBmgiwABNBBigiQADNBFggCYCDNBEgAGaCDBAEwEGaCLAAE0EGKCJAAM0EWCAJgIM0ESAAZoIMEATAQZoIsAATQQYoIkAAzQRYIAmAgzQRIABmtyQAC8uLuad73xnFhcXr3vM4cOHc/r06Zw+fToPPPDAmsc99dRTOXPmTBYWFnZqudykLp9nCwsLV3283nkHG9lMvyZ1QwJ84sSJnDlzJg8++OB1jzl37tyV++sde+7cuVy6dCn333//tq+Tm9vl8+z++++/6uP1zjvYyGb6NakdD/Di4mJOnjyZMUZOnjy55rPI4uJiHnrooWu2P/nkk1fdX1hYyNNPP50kOXv2rFfBXLHyPDt79uxVH9c772Ajm+nXNHY8wCdOnMilS5eSJBcvXlzzWeTEiRO5ePHiNdvPnz+fXLqYXLqYhYWF3HvvvVft9yqYy1aeZ6utd97BRjbTr2lsGOCqekdVzVfV/Pnz57f8BR599NFcuHAhSXLhwoU88sgjax6zGZdf/V529uzZLa+HvWnlebbaeucdbGQz/ZrGhgEeY7x3jHFwjHHw9ttv3/IXePOb35yZmZkkyczMTN7ylresecz6K9yf7Nufubm5zM7OXrVr9X2evVaeZ6utd97BRjbTr2ns+CWII0eOZN++pS+zf//+HD58eM1j9u/ff8321cG/7777rnufZ6+V59lq6513sJHN9GsaOx7g2267LYcOHUpV5dChQ7ntttvWPObuu+++Zvsdd9xx1f25ubnccsstSZZe/c7Nze3MornprDzPZmdnr/q43nkHG9lMv6ZxQ/4Z2pEjR/KqV73qus8eR44cyZ133nnl/nrH3nnnndm3b59Xv1zj8nl23333XfXRq1+msZl+TarGGJs++ODBg2N+fn7bF7HSsWPHkiTvfve7c+zYsTz+2X9JkvzwD7ziyrbL+wFuBlV1aoxxcPV2P4oM0ESAAZoIMEATAQZoIsAATQQYoIkAAzQRYIAmAgzQRIABmggwQBMBBmgiwABNBBigiQADNBFggCYCDNBEgAGaCDBAEwEGaCLAAE0EGKCJAAM0EWCAJgIM0ESAAZoIMEATAQZoIsAATQQYoIkAAzQRYIAmAgzQRIABmggwQBMBBmgiwABNBBigyUz3Alabm5ubaj/AzWLXBfjo0aNT7Qe4WbgEAdBEgAGaCDBAEwEGaCLAAE0EGKCJAAM0EWCAJgIM0ESAAZoIMEATAQZoIsAATQQYoIkAAzQRYIAmAgzQRIABmggwQBMBBmgiwABNBBigiQADNBFggCYCDNBEgAGaCDBAEwEGaCLAAE0EGKCJAAM0EWCAJgIM0ESAAZoIMEATAQZoIsAATQQYoIkAAzQRYIAmM90L2NDFC90rANgRuzrAc3NzeeKJJ67cBthLaoyx6YMPHjw45ufnd3A5AHtPVZ0aYxxcvd01YIAmAgzQRIABmggwQBMBBmgiwABNBBigiQADNBFggCYCDNBEgAGaCDBAEwEGaCLAAE0EGKCJAAM0EWCAJgIM0ESAAZoIMECTLf1Szqo6n+TLW/j8B5J8fauL2sX20jx7aZZkb82zl2ZJ9tY8k87y3WOM21dv3FKAt6qq5tf6TaA3q700z16aJdlb8+ylWZK9Nc92z+ISBEATAQZostMBfu8Of/4bbS/Ns5dmSfbWPHtplmRvzbOts+zoNWAA1ucSBEATAQZoMnGAq+psVZ2pqseran6N/W+rqn++vL+qfmzFvt+sqs9V1Wer6i+r6nmTrmM7bDTLiuN+pKouVtU9K7Ydqqp/raqFqvrdG7Pi65t0nqp6WVX9fVV9fvnxOXbjVr3uGid+bJa376+qz1TVx3d+tRub8lx7cVV9uKq+sPwYve7GrHrdNU4zy65qwPKaNmram6rqG8v7H6+q31+xb7IOjDEm+pPkbJID19n/gjxzjfkHk3xh+fZLknwpyfOX7/9Vkl+cdB3b8WejWZaP2Z/k75I8nOSeFdv+PcnLkzw3yekkr+icZcp5vivJXcu3X5jk37rnmXSWFft+K8kHk3y8+3GZdp4kJ5L8yvLt5yZ58c04y25swGbmSfKmtc6jaTqwY5cgxhj/M5ZXl+TWJCvf7ZtJ8vyqmknybUme3Kl1bKOjSf46yddWbHtNkoUxxhfHGN9K8qEkb+tY3ASumWeM8dUxxqeXb/93ks9n6Ztlt1vrsUlVvTTJ3Une17GoKVwzT1W9KMkbkvxZkowxvjXG+M+W1W3Nmo9Nbs4GrGfiDkwT4JHkE1V1qqresdYBVfX2qvpCkoeS/HKSjDGeSPLHSc4l+WqSb4wxPjHFOrbDdWepqpckeXuS96za9ZIk/7Hi/leyO4I16Twrj5lN8uokn9qpRW7SNLO8K8lvJ7m0oyvcmknneXmS80n+fPmSyvuq6tadX+51TTTLLm1AsommJXldVZ2uqr+pqlcub5u4A9ME+PVjjLuS/ESSe6vqDasPGGN8dIzx/Ul+OskfJklVfXuWnh2+J8kdSW6tqp+fYh3bYaNZ3pXkd8YYF1dtrzU+1274d32TzpMkqaoXZOlVy2+MMf5rR1e6sYlmqaqfTPK1McapG7PMTZv0sZlJcleSPx1jvDrJ/ybpfs9h0sdmNzYg2XieT2fp/3T4oSTHk3xsefvEHZiZcKEZYzy5/PFrVfXRLL0M/+Q6x36yqr63qg4k+fEkXxpjnE+SqvpIkh9N8v5J1zKtTcxyMMmHqipZ+s843lpVF7L0TPeyFce9NLvgr1KTzjPG+FhVPSdL8f3AGOMjN3jp15jisXltkp+qqrcmeV6SF1XV+8cYrd/oU8zzT0m+Msa4/DeSD6c5wFPM8pzssgYkG8+z8sXIGOPhqvqT5aZN3oEJL1bfmuSFK27/Y5JDq46ZyzNvwt2V5IksPVO8NsnnsnTdp7L0xsLRxgvvG86y6vi/yDNvJswk+WKWnskvX3x/Zdcs2zBPJXkwybs6Z9iOWVZtf1N2wZtw086T5B+SfN/y7T9I8kc34yy7rQGbnSfJd65o2muydAmlpunApK+AvyPJR5ef2WaSfHCMcbKqfjVJxhjvSfIzSQ5X1f8l+WaSnx1LK/9UVX04Sy/nLyT5THp/VHEzs6xpjHGhqn49yd9m6Z3QB8YYn7sBa76eiedJ8vokv5DkTFU9vrzt98YYD+/geq9nmll2o2nnOZrkA1X13Cx9w//STi52A9N83+y2BiSbm+eeJL+2/Cr+m0l+brlpE3fAjyIDNPGTcABNBBigiQADNBFggCYCDNBEgAGaCDBAk/8Hm7BG+NuxQ8cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.boxplot(x=quality_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.688\n",
      "RMSE: 0.714\n"
     ]
    }
   ],
   "source": [
    "#with Standard Scaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "X = cookies.drop(['quality'], axis=1)\n",
    "y = cookies['quality']\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#scaling the x values\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scale = scaler.transform(X_train)\n",
    "X_test_scale = scaler.transform(X_test)\n",
    "\n",
    "Knn = KNeighborsRegressor(n_neighbors = 18, weights = 'distance')\n",
    "Knn.fit(X_train_scale, y_train)\n",
    "y_pred = Knn.predict(X_test_scale)\n",
    "print('R2:', round(r2_score(y_test, y_pred), 3))\n",
    "print('RMSE:', round(mean_squared_error(y_test, y_pred, squared=False), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "query data dimension must match training data dimension",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-f34ad1cd2985>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#scaling test data set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mquality_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mquality_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_regression.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    660\u001b[0m                 \u001b[0mdelayed_query\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_tree_query_parallel_helper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m                 \u001b[0mparallel_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"prefer\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"threads\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 662\u001b[1;33m             chunked_results = Parallel(n_jobs, **parallel_kwargs)(\n\u001b[0m\u001b[0;32m    663\u001b[0m                 delayed_query(\n\u001b[0;32m    664\u001b[0m                     self._tree, X[s], n_neighbors, return_distance)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1046\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1048\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    864\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36m_tree_query_parallel_helper\u001b[1;34m(tree, *args, **kwargs)\u001b[0m\n\u001b[0;32m    490\u001b[0m     \u001b[0munder\u001b[0m \u001b[0mPyPy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m     \"\"\"\n\u001b[1;32m--> 492\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msklearn\\neighbors\\_binary_tree.pxi\u001b[0m in \u001b[0;36msklearn.neighbors._kd_tree.BinaryTree.query\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: query data dimension must match training data dimension"
     ]
    }
   ],
   "source": [
    "#scaling test data set\n",
    "scaler.fit(test)\n",
    "quality_pred = Knn.predict(test)\n",
    "quality_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=quality_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
